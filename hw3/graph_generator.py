import matplotlib.pyplot as plt
from pylab import *

plt.clf()

# these must have the same dimension
# number of clusters (K)
xs = range(1,11)

# number of iterations
#xs = range(1,43)

# MSE
#ys = [1.97360905671, 1.74778748234, 1.65399446656, 1.45009995433, 1.33467421783, 1.44166487051, 1.2661665223, 1.25232064349, 1.26522099893, 1.15731114013]
#ys = [1.97360905671, 1.88100151706, 1.64963377791, 1.53424314422, 1.49196558677, 1.26277282488, 1.31338526986, 1.29026389502, 1.22227876667, 1.18138043207]

# neither of the above was great, so i averaged them!
#ys = [(a+b)/2 for a,b in zip([1.97360905671, 1.74778748234, 1.65399446656, 1.45009995433, 1.33467421783, 1.44166487051, 1.2661665223, 1.25232064349, 1.26522099893, 1.15731114013], [1.97360905671, 1.88100151706, 1.64963377791, 1.53424314422, 1.49196558677, 1.26277282488, 1.31338526986, 1.29026389502, 1.22227876667, 1.18138043207])]
ys = [1.96918172904, 1.68314345418, 1.50131306327, 1.37279848621, 1.2687726529, 1.16471046971, 1.15189702303, 1.12488165325, 1.1488899471, 1.06014589539]


# log likelihoods
#ys = [-14782.1584421, -14268.262248, -13552.8713223, -13022.579198, -12646.6686475, -12574.5456916, -12495.9449962, -12420.0909427, -12354.8151671, -12296.1541728, -12269.4601923, -12259.6464801, -12251.9526558, -12243.8494685, -12234.3667545, -12210.8915098, -12205.4585935, -12202.6158156, -12198.9654853, -12193.1305449, -12180.8406822, -12173.1715897, -12171.5307713, -12168.3947365, -12165.7164009, -12164.5421517, -12163.7279417, -12163.2859655, -12162.846995, -12162.6005823, -12162.4363103, -12162.3319915, -12162.2637601, -12162.2188407, -12162.1891174, -12162.1693899, -12162.1563154, -12162.1477619, -12162.142415, -12162.139555, -12162.1389572, -12162.1409034]
#ys = [-14456.595743, -14269.7809269, -13899.2602589, -12150.1443146, -12103.1232444, -12287.0962841, -12210.7942808, -11601.3797226, -11903.0846218, -11848.3002445]

p1, = plt.plot(xs, ys, color='b')

plt.grid(b=1)

#plt.title('Mean Squared Error vs. K on 1000 Examples')
plt.title('Log Likelihood vs. Iterations on 1000 Examples, K = 4')
#plt.title('Log Likelihood vs. K on 1000 Examples')
plt.xlabel('K')
#plt.xlabel('Iteration')
plt.ylabel('Mean Squared Error')
#plt.ylabel('Log Likelihood')
plt.axis([0,11,0,2.2])
#plt.axis([0,11,-10000,-14600])
#plt.legend((p1), ('Training Accuracy',), 'lower right')

# save figure as a pdf
savefig('mse-vs-k.pdf')
#savefig('autoclass-likelihoods.pdf')
#savefig('autoclass-likelihoods-v-k.pdf')


